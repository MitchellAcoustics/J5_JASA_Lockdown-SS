{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1598376955134",
   "display_name": "Python 3.7.5 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# London Lockdown Multilevel Model\n",
    "\n",
    "For our model, we will be building a linear mixed effects model for each target output variable (e.g. `Pleasant`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "sys.path.append(\"C:\\\\Users\\\\Andrew\\\\OneDrive - University College London\\\\_PhD\\\\Papers - Drafts\\\\J5_JASA_Lockdown-SS\")\n",
    "\n",
    "from scripts import lockdown_mlm as mlm\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"ticks\")\n",
    "sns.set_context(\"paper\", font_scale=1.4)\n",
    "\n",
    "# Define some constants and options\n",
    "## variables\n",
    "dep_vars = [\"Natural\", \"Traffic\", \"Human\", \"Other\", \"loudness\", \"overall\", \"Pleasant\", \"Eventful\"]\n",
    "\n",
    "FEATS_LISTS = mlm.FEATS_LISTS\n",
    "remove = [\"FS_TEMP\", \"LAeq_TEMP\", \"LCeq_TEMP\", \"LZeq_TEMP\", \"I_TEMP\", \"N_TEMP\", \"R_TEMP\", \"S_TEMP\", \"SIL_TEMP\", \"THD_TEMP\", \"T_TEMP\"]\n",
    "\n",
    "for k in remove:\n",
    "    FEATS_LISTS.pop(k, None)\n",
    "\n",
    "acoustic_vars = sorted({x for v in FEATS_LISTS.values() for x in v})\n",
    "\n",
    "## processing options\n",
    "nonlinear_transformations = []\n",
    "criterion = \"aic\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = Path(\"C:\\\\Users\\\\Andrew\\\\OneDrive - University College London\\\\_PhD\\\\Papers - Drafts\\\\J5_JASA_Lockdown-SS\\\\data\")\n",
    "ssidData = pd.read_csv(DATA_DIR.joinpath(\"2020-08-13\\\\LondonVeniceBINResults_2020-08-13_4.csv\"))\n",
    "\n",
    "for col_name in [\"Lockdown\"]:\n",
    "    ssidData[col_name] = ssidData[col_name].astype('category')\n",
    "\n",
    "ssidData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cutdown the dataset\n",
    "cols = [\"GroupID\", \"LocationID\", \"SessionID\", \"Lockdown\"] + dep_vars + acoustic_vars\n",
    "ssidData = ssidData[cols]\n",
    "\n",
    "# Compress to mean of each GroupID\n",
    "# compressData = ssidData.copy()\n",
    "compressData = ssidData.groupby([\"GroupID\"]).mean()\n",
    "compressData = compressData.merge(ssidData[[\"GroupID\", \"LocationID\", \"SessionID\", \"Lockdown\"]].drop_duplicates(),  on=\"GroupID\")\n",
    "\n",
    "location_codes = pd.Categorical(compressData[\"LocationID\"]).codes\n",
    "compressData[\"LocationID_codes\"] = location_codes\n",
    "compressData.loc[compressData[\"Lockdown\"] == 1].dropna(inplace=True)\n",
    "compressData = compressData.dropna(subset=acoustic_vars)\n",
    "\n",
    "print(compressData.shape)\n",
    "compressData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "compressData, acoustic_vars = mlm.nonlinear_features(compressData, acoustic_vars, transformations=nonlinear_transformations)\n",
    "print(acoustic_vars)\n",
    "compressData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Standardise\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "compressData = compressData.replace([np.inf, -np.inf], np.nan)\n",
    "compressData = compressData.dropna(subset=acoustic_vars)\n",
    "scaler = StandardScaler()\n",
    "compressData[acoustic_vars] = scaler.fit_transform(compressData[acoustic_vars])\n",
    "print(compressData.shape)\n",
    "compressData.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into pre- and during-lockdown datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prelockdownData = compressData.loc[compressData[\"Lockdown\"] == 1]\n",
    "prelockdownData = prelockdownData.dropna()\n",
    "print(prelockdownData.shape)\n",
    "prelockdownData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "lockdownData = compressData.loc[compressData[\"Lockdown\"] == 2]\n",
    "print(lockdownData.shape)\n",
    "lockdownData.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking distribution of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(prelockdownData[[\"LocationID\", \"Pleasant\", \"Eventful\"]], col=\"LocationID\", col_wrap=4, xlim=(-1,1), legend_out=True)\n",
    "g.map(sns.distplot, \"Pleasant\", rug=True, hist=False)\n",
    "g.map(sns.distplot, \"Eventful\", rug=True, hist=False, color=\"y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,8))\n",
    "fig.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "for i in range(len(dep_vars)):\n",
    "    ax = fig.add_subplot(2, 4, i+1)\n",
    "    bins=None\n",
    "    kde_kws=None\n",
    "    if dep_vars[i] not in [\"Pleasant\", \"Eventful\"]:\n",
    "        bins=5\n",
    "        kde_kws = {\"bw\": 0.5}\n",
    "    sns.distplot(prelockdownData[dep_vars[i]], ax=ax, bins=bins, kde_kws=kde_kws, rug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.FacetGrid(prelockdownData[[\"LocationID\", \"loudness\"]], col=\"LocationID\", col_wrap=4, xlim=(0.5,5.5))\n",
    "g.map(sns.distplot, \"loudness\", kde_kws={\"bw\":0.5}, bins=[0.5, 1.5, 2.5, 3.5, 4.5, 5.5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = sns.lmplot(x = \"LCeq_10\", y = \"Pleasant\", col = \"LocationID\", sharex = False, col_wrap = 4, data = prelockdownData, height=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection and Model Building\n",
    "\n",
    "### Backward step feature selection\n",
    "In order to filter out the massive number of potential features, we want to determine which ones significantly contribute to the final model. To do this, we use backward step feature selection which starts by including all possible features and gradually reduces them based on their p-values. This follows 6 steps:\n",
    "\n",
    "![](https://miro.medium.com/max/700/1*Jub_nEYtN0htxFpTRzRtBQ.png)\n",
    "\n",
    "#### Step 1\n",
    "Select a significance level to use as the criterion for selection. Typically, this will be 0.05.\n",
    "\n",
    "#### Step 2\n",
    "Fit the model with all the features selected.\n",
    "\n",
    "#### Step 3\n",
    "Identify the feature with the highest p-value (i.e. least statistically significant).\n",
    "\n",
    "#### Step 4\n",
    "If the p-value of this feature is greater than the significance level (e.g. p-value is > 0.05), we remove it from the feature set. If the highest p-value is less than the significance level, skip to step 6 and finish.\n",
    "\n",
    "#### Step 5\n",
    "Remove the feature from the set and fit a new model. Return to step 3 and repeat until all features have a p-value below the significance level.\n",
    "\n",
    "#### Step 6\n",
    "We have now identified the feature set, so fit the final model.\n",
    "\n",
    "This results in a drastically cut down feature set, which is good, but it's still a very complex model, resulting in a low adjusted r-squared value. We've identified all of the potentially significant features, but we still need to do further feature selection. For this, we move onto forward step feature selection with the Akaike Information Criterion as our criterion.\n",
    "\n",
    "### Forward Step Feature selection\n",
    "https://planspace.org/20150423-forward_selection_with_statsmodels/\n",
    "\n",
    "In forward step selection, we build a model for each potential feature individually, calculate the best performing model, and select that feature. We then add every other feature to it and build n-1 two-feature models, then calculate the best performing model and select those two features. This continues until adding features to the model no longer improves its criterion performance. \n",
    "\n",
    "It is important in this method to use a criterion which punishes model complexity, otherwise the model will always improve by adding new features.\n",
    "\n",
    "Success! We can see that this method has reduced the features even further. However, I suspect there are some issues with multicollinearity, so we'll tackle that next.\n",
    "\n",
    "### Reducing multi-collinearity\n",
    "We've identified multi-collinearity among several of the features which were selected by the backward-forward feature selection. This is identified through the Variance Inflation Factor (VIF). We've set the max acceptable VIF at a fairly high level of 10 to be very lenient to our potential features. To address this, we remove the highest VIF feature and re-build the model, then check the VIF again. We do this until the max VIF feature is below our set criterion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature selection and model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = {}\n",
    "back_models = {}\n",
    "forward_models = {}\n",
    "vifs = {}\n",
    "for var in dep_vars:\n",
    "    try:\n",
    "        print(\"\\n###########################################################\")\n",
    "        print(f\"\\nPERFORMING FEATURE SELECTION AND MODEL BUILDING FOR {var}.\")\n",
    "        print(\"\\n###########################################################\\n\")\n",
    "        model, back, forward, vif = mlm.mlm_feature_selection(prelockdownData, var, acoustic_vars, \"LocationID\", criterion=\"aic\", verbose=0)\n",
    "\n",
    "        print(\"\\n=========================================================\")\n",
    "        print(f\"\\nFINAL MODEL FOR {var}.\\n\")\n",
    "        mlm.summarise_model(model, prelockdownData)\n",
    "\n",
    "        models[var] = model\n",
    "        back_models[var] = back\n",
    "        forward_models[var] = forward\n",
    "        vifs[var] = vif\n",
    "\n",
    "    except:\n",
    "        print(f\"Ran into an unresolvable error for {var} model. Moving on.\")\n",
    "        continue\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use the models to predict the values for the during lockdown data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for model in models:\n",
    "    lockdownData[f\"{model}_pred\"] = models[model].predict(lockdownData)\n",
    "\n",
    "p = sns.pairplot(x_vars=[\"Pleasant\"], y_vars=[\"Eventful\"], data = prelockdownData, hue =\"LocationID\", size = 8)\n",
    "p.set(xlim = (-1,1))\n",
    "p.set(ylim= (-1,1))\n",
    "plt.show()\n",
    "\n",
    "l = sns.pairplot(x_vars=[\"Pleasant_pred\"], y_vars=[\"Eventful_pred\"], data = lockdownData, hue =\"LocationID\", size = 8)\n",
    "l.set(xlim = (-1,1))\n",
    "l.set(ylim= (-1,1))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from statsmodels.regression.mixed_linear_model import MixedLMResults\n",
    "Pleasant_model = MixedLMResults.load(\"C:\\\\Users\\\\Andrew\\\\OneDrive - University College London\\\\_PhD\\Papers - Drafts\\\\J5_JASA_Lockdown-SS\\\\results\\\\2020-08-21\\\\Pleasant_RI-only_2020-08-21.pickle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(Pleasant_model.model.exog_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}