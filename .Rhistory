grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
lm.model.building <- function(target, features, train, test, exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lm(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model)
if (verbose >= 2) {print(step.model)}
scaled.model <- step.model
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lm(formula, data=train)
if (verbose > 1) {
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model R-squared:")
# print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lm.pred.plots(model, target, train.data, test.data, grp="LocationID", plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lm.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
lm.location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE)
Eventful.results$scaled.model
car::vif(Eventful.results$scaled.model)
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"))
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"), verbose=1)
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"))
car::vif(Eventful.results$scaled.model)
Eventful.results$scaled.model$rank
Eventful.results$scaled.model$effects
tab_model(Eventful.results$scaled.model, show.std = "std")
tab_model(Eventful.results$model, show.std = "std")
Eventful.results$model
tab_model(Eventful.results$model)
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"), scale=TRUE)
Eventful.results$scaled.model
View(test.data)
View(test)
lm.model.building <- function(target, features, train, test, exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string))
test.data <<- test
train.data <<- train
train.data[c(features)] <<- scale(train.data[c(features)])
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lm(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model)
if (verbose >= 2) {print(step.model)}
scaled.model <- step.model
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lm(formula, data=train)
if (verbose > 1) {
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model R-squared:")
# print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lm.pred.plots(model, target, train.data, test.data, grp="LocationID", plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lm.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
lm.location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"), scale=TRUE)
Eventful.results$scaled.model
lm.model.building <- function(target, features, train, test, exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <<- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lm(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model)
if (verbose >= 2) {print(step.model)}
scaled.model <- step.model
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lm(formula, data=train)
if (verbose > 1) {
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model R-squared:")
# print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lm.pred.plots(model, target, train.data, test.data, grp="LocationID", plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lm.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
lm.location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
# Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=2, pred=TRUE, plot=TRUE)
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, exclude.features = c("N5"), scale=TRUE)
library(lmerTest)
lmer.model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <<- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, reduce.random=TRUE)
if (verbose >= 2) {print(step.model)}
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lmer.pred.plots(model, target, train.data, test.data, grp=grp, plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lmer.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = c("FS" + "PA" + "N5"), train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = c("FS", "PA", "N5"), train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
sjPlot::tab_model(Pleasant.results$model, Eventful.results$model)
sjPlot::tab_model(Pleasant.results$scaled.model, Eventful.results$scaled.model)
sjPlot::plot_models(Pleasant.results$scaled.model, Eventful.results$scaled.model, std.est='std', show.values = TRUE)
lockdownData$ISOPleasant <- predict(Pleasant.results$model, newdata=lockdownData)
lockdownData$ISOEventful <- predict(Eventful.results$model, newdata=lockdownData)
# lockdownData$Natural <- predict(Natural.mod, newdata=lockdownData)
# lockdownData$Human <- predict(Human.mod, newdata=lockdownData)
# lockdownData$Traffic <- predict(Traffic.mod, newdata=lockdownData)
print(head(lockdownData))
write.csv(lockdownData, glue("Predicted Lockdown Data_", format(Sys.Date()), "_2", ".csv"), row.names = FALSE)
?step
