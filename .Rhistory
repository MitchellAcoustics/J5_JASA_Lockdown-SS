parts = partition(prelockdownData, p=0.2, id_col="LocationID")
train = parts[[1]]
test = parts[[2]]
print(train)
summary(train)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, id_col="LocationID")
train = parts[[1]]
test = parts[[2]]
summary(train)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, id_col="LocationID")
train = parts[[1]]
test = parts[[2]]
kable(summary(train))
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, id_col="LocationID")
train = parts[[1]]
test = parts[[2]]
summary(train)
summar(test)
summary(test)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[1]]
test = parts[[2]]
summary(train)
summary(test)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
summary(train)
summary(test)
Pleasant_formula <- as.formula(glue("Pleasant ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Pleasant_model <- lmerTest::lmer(Pleasant_formula, data = train)
step_Pleasant_model <- lmerTest::step(init_Pleasant_model, data = train, reduce.random=TRUE)
step_Pleasant_model
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model)
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model, data=train)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
prelockdownData[c(features)] <- scale(prelockdownData[c(features)])
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
summary(train)
summary(test)
Pleasant_formula <- as.formula(glue("Pleasant ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Pleasant_model <- lmerTest::lmer(Pleasant_formula, data = train)
step_Pleasant_model <- lmerTest::step(init_Pleasant_model, data = train, reduce.random=TRUE)
View(prelockdownData)
step_Pleasant_model
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model, data=train)
library(readxl)
library(glue)
library(tidyr)
library(knitr)
data <- read_csv(here("data", "2021-04-16", "LondonVeniceBINResults_2020-08-13.csv"))
library(readr)
library(glue)
library(tidyr)
library(knitr)
data <- read_csv(here("data", "2021-04-16", "LondonVeniceBINResults_2020-08-13.csv"))
library(readr)
library(glue)
library(tidyr)
library(knitr)
data <- read_csv(here("data", "2021-04-16", "LondonVeniceBINResults_2020-08-13_4.csv"))
data <- as_tibble(data)
data <- data[c("GroupID", "LocationID", "Lockdown", "Pleasant", "Eventful", "Human", "Traffic", "Natural", features)]
features <- c("N_5", "S", "R", "I", "FS", "LAeq", "LAeq_10_LAeq_90", "LCeq_LAeq", "SIL.rms.", "PeakSpectralCentroid")
feature_string <- paste(features, collapse = " + ")
feature_string
library(readr)
library(glue)
library(tidyr)
library(knitr)
data <- read_csv(here("data", "2021-04-16", "LondonVeniceBINResults_2020-08-13_4.csv"))
data <- as_tibble(data)
data <- data[c("GroupID", "LocationID", "Lockdown", "Pleasant", "Eventful", "Human", "Traffic", "Natural", features)]
View(data)
names(data)
features <- c("N_5", "S", "R", "I", "FS", "LAeq", "LAeq_10_LAeq_90", "LCeq_LAeq", "SIL_50", "PeakSpectralCentroid")
feature_string <- paste(features, collapse = " + ")
feature_string
library(readr)
library(glue)
library(tidyr)
library(knitr)
data <- read_csv(here("data", "2021-04-16", "LondonVeniceBINResults_2020-08-13_4.csv"))
data <- as_tibble(data)
data["LCeq_LAeq"] <- data$LCeq - data$LAeq
data <- data[c("GroupID", "LocationID", "Lockdown", "Pleasant", "Eventful", "Human", "Traffic", "Natural", features)]
print("Full data table has dimensions: ")
print(dim(data))
print(data)
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
data <- data %>% mutate_at(vars(c("Pleasant", "Eventful", "Traffic", "Human", "Natural", features)), funs(as.numeric))
head(data)
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
prelockdownData[c(features)] <- scale(prelockdownData[c(features)])
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
summary(train)
summary(test)
Pleasant_formula <- as.formula(glue("Pleasant ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Pleasant_model <- lmerTest::lmer(Pleasant_formula, data = train)
step_Pleasant_model <- lmerTest::step(init_Pleasant_model, data = train, reduce.random=TRUE)
step_Pleasant_model
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model, data=train)
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model, data=test)
MuMIn::r.squaredGLMM(Pleasant_model, data=train)
install.packages("caret")
predictions <- predict(Pleasant_model, test)
predictions
MuMIn::r.squaredGLMM(predictions)
Pleasant_model <- lmerTest::get_model(step_Pleasant_model)
# Pleasant_model <- lmerTest::step(Pleasant_formula, data = prelockdownData, REML=FALSE)
sjPlot::tab_model(Pleasant_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Pleasant_model, type="re", title = "Random effects - Pleasant", show.values = TRUE)
sjPlot::plot_model(Pleasant_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Pleasant_model)
Eventful_formula <- as.formula(glue("Eventful ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Eventful_model <- lmerTest::lmer(Eventful_formula, data = prelockdownData)
step_Eventful_model <- lmerTest::step(init_Eventful_model, data = prelockdownData)
Eventful_formula <- as.formula(glue("Eventful ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Eventful_model <- lmerTest::lmer(Eventful_formula, data = train)
step_Eventful_model <- lmerTest::step(init_Eventful_model, data = train)
step_Eventful_model
Eventful_model <- lmerTest::get_model(step_Eventful_model)
sjPlot::tab_model(Eventful_model, show.icc = TRUE, collapse.ci = TRUE, show.aic = TRUE)
sjPlot::plot_model(Eventful_model, type="re", title = "Random effects - Eventful", show.values = TRUE)
sjPlot::plot_model(Eventful_model, show.values = TRUE)
MuMIn::r.squaredGLMM(Eventful_model)
?mutate_at
knit_with_parameters('C:/Users/mitch/OneDrive - University College London/_PhD/Papers - Drafts/J5_JASA_Lockdown-SS/notebook/2021-04-14/New features Lockdown Modelling.Rmd')
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
data <- data %>% mutate_at(vars(c("Pleasant", "Eventful", "Traffic", "Human", "Natural", features)), funs(as.numeric))
kable(head(data))
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
prelockdownData[c(features)] <- scale(prelockdownData[c(features)])
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
kable(summary(train))
kable(summary(test))
Pleasant_formula <- as.formula(glue("Pleasant ~ 1 + ", feature_string, " + (1 + ", feature_string, "|LocationID)"))
init_Pleasant_model <- lmerTest::lmer(Pleasant_formula, data = train)
step_Pleasant_model <- lmerTest::step(init_Pleasant_model, data = train, reduce.random=TRUE)
kable(step_Pleasant_model)
kable(step_Eventful_model)
kable(summary(step_Eventful_model))
kable(print(step_Eventful_model))
?lmerTest::step
step$random
step_Eventful_model$random
step_Eventful_model$fixed
kable(step_Eventful_model$fixed)
kable(step_Eventful_model$random)
kable(MuMIn::r.squaredGLMM(Pleasant_model))
install.packages("lmerTest")
library(lmerTest)
install.packages("lmerTest")
library(lmerTest)
require(devtools)
install.packages("devtools")
install.packages("devtools")
require(devtools)
packageurl <- "https://cran.r-project.org/src/contrib/Archive/lmmlasso/lmmlasso_0.1-2.tar.gz"
install.packages(packageurl, repos=NULL, type="source")
knitr::opts_chunk$set(echo = TRUE)
init_features <- c("Loudness_N5(soneGF)", "Sharpness_S(acum)", "Rough_HM_R(asper)", "I_HM_I(iu)", "FS_(vacil)", "LAeq_L(A)(dB(SPL))", "LA10_LA90(dB(SPL))", "LCeq_LAeq(dB(SPL))", "SIL3_Avg,arith(dB(SPL))")
init_feature_string <- paste(init_features, collapse = " + ")
init_feature_string
library(glue)
library(tidyr)
library(here)
library(knitr)
library(dplyr)
library(readxl)
data <- read_excel(here("data", "2021-05-05", "SSID Europe Database V1.0.xlsx"), sheet = "Master Merge")
data <- as_tibble(data)
data <- data[c("GroupID", "LocationID", "Lockdown", "ISOPleasant", "ISOEventful", "Human", "Traffic", "Natural", init_features)]
data <- rename(data, "N5" = "Loudness_N5(soneGF)")
data <- rename(data, "S" = "Sharpness_S(acum)")
data <- rename(data, "R" = "Rough_HM_R(asper)")
data <- rename(data, "I" = "I_HM_I(iu)")
data <- rename(data, "FS" = "FS_(vacil)")
data <- rename(data, "LAeq" = "LAeq_L(A)(dB(SPL))")
data <- rename(data, "LA10_LA90" = "LA10_LA90(dB(SPL))")
data <- rename(data, "LCeq_LAeq" = "LCeq_LAeq(dB(SPL))")
data <- rename(data, "SIL3" = "SIL3_Avg,arith(dB(SPL))")
features <- c("N5", "S", "R", "I", "FS", "LAeq", "LA10_LA90", "LCeq_LAeq", "SIL3")
feature_string <- paste(features, collapse = " + ")
feature_string
print("Full data table has dimensions: ")
print(dim(data))
kable(print(data))
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
data <- data %>% mutate_at(vars(c("ISOPleasant", "ISOEventful", "Traffic", "Human", "Natural", features)), funs(as.numeric))
kable(head(data))
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
prelockdownData[c(features)] <- scale(prelockdownData[c(features)])
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
kable(summary(train))
library(lme4)
library(afex)
# library(RePsychLink)
library(glmmLasso)
library(dplyr)
library(tidyr)
library(MASS)
library(nlme)
library(emmeans)
library(tibble)
library(caret)
library(ggpubr)
set.seed(42)
lassoData <- drop_na(prelockdownData)
# five-fold cross validation
train.control.CV5 <- trainControl(method="cv", number=5)
# range of lambdas to check
Lambda.Range = 10^seq(-3,3,length=100)
# Run our LASSO model, testing all possible interactions
Lasso <- train(ISOPleasant ~ N5*S*R*I*FS*LAeq*LA10_LA90*LCeq_LAeq*SIL3, data=lassoData, method="glmnet", metric="RMSE", trControl=train.control.CV5, lambda=Lambda.Range, tuneGrid=expand.grid(alpha=1, lambda=Lambda.Range)) #alpha=1 means LASSO
Lasso.Data <- tibble(Lambda=Lasso$finalModel$lambda,
N5.z=coef(Lasso$finalModel)[2,],
S.z=coef(Lasso$finalModel)[3,],
R.z=coef(Lasso$finalModel)[4,],
I.z=coef(Lasso$finalModel)[5,],
FS.z=coef(Lasso$finalModel)[6,],
LAeq.z=coef(Lasso$finalModel)[7,],
LA10_LA90.z=coef(Lasso$finalModel)[8,],
LC_LA.z=coef(Lasso$finalModel)[9,],
SIL3.z=coef(Lasso$finalModel)[10,]) %>% gather(Variables, Coef, N5.z:SIL3.z)
#set up this DF for the plots
Lasso.Fit <- tibble(lambda=Lasso$results$lambda,
RMSE=Lasso$results$RMSE,
R2=Lasso$results$Rsquared)
#Plots of results
Coef.Plot <- ggplot(Lasso.Data, aes(Lambda, Coef, group=Variables))+
geom_smooth(aes(color=Variables), method="loess", se=FALSE)+
scale_x_log10(
breaks=scales::trans_breaks("log10", function(x) 10^x),
labels=scales::trans_format("log10", scales::math_format(10^.x))
)+
xlab("Lambda")+theme_bw()
RMSE.Plot <- ggplot(Lasso.Fit, aes(lambda, RMSE))+
geom_smooth(method="loess", se=FALSE)+
scale_x_log10(
breaks=scales::trans_breaks("log10", function(x) 10^x),
labels=scales::trans_format("log10", scales::math_format(10^.x))
)+
xlab("Lambda")+theme_bw()
R2.Plot <- ggplot(Lasso.Fit, aes(lambda, R2))+
geom_smooth(method="loess", se=FALSE)+
scale_x_log10(
breaks=scales::trans_breaks("log10", function(x) 10^x),
labels=scales::trans_format("log10", scales::math_format(10^.x))
)+
xlab("Lambda")+theme_bw()
ggarrange(Coef.Plot,
ggarrange(RMSE.Plot, R2.Plot, ncol=2, labels=c("B","C")),
nrow=2,
labels="A"
)
round(coef(Lasso$finalModel, Lasso$finalModel$lambdaOpt), 4)
?glmmLasso
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1), lambda=10, data=lassoData)
summary(mod)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1), lambda=10, data=lassoData)
summary(mod)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), lambda=10, data=lassoData)
summary(mod)
plot(mod, plot.data=FALSE)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), lambda=100, data=lassoData)
summary(mod)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), lambda=1, data=lassoData)
summary(mod)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), lambda=5, data=lassoData)
summary(mod)
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), lambda=1, data=lassoData)
summary(mod)
mod$ranef
library(glmmLasso)
mod <- glmmLasso(ISOPleasant ~ N5 + S + R + I + FS + LA10_LA90, rnd = list(LocationID=~1 + N5 + S + R), family=gaussian(), lambda=10, data=lassoData)
summary(mod)
demo("glmmLasso-soccer")
knitr::opts_chunk$set(echo = TRUE)
init_features <- c("Loudness_N5(soneGF)", "Sharpness_S(acum)", "Rough_HM_R(asper)", "I_HM_I(iu)", "FS_(vacil)", "LAeq_L(A)(dB(SPL))", "LA10_LA90(dB(SPL))", "LCeq_LAeq(dB(SPL))", "SIL3_Avg,arith(dB(SPL))")
init_feature_string <- paste(init_features, collapse = " + ")
init_feature_string
library(glue)
library(tidyr)
library(here)
library(knitr)
library(dplyr)
library(readxl)
data <- read_excel(here("data", "2021-05-05", "SSID Europe Database V1.0.xlsx"), sheet = "Master Merge")
data <- as_tibble(data)
data <- data[c("GroupID", "LocationID", "Lockdown", "ISOPleasant", "ISOEventful", "Human", "Traffic", "Natural", init_features)]
data <- rename(data, "N5" = "Loudness_N5(soneGF)")
data <- rename(data, "S" = "Sharpness_S(acum)")
data <- rename(data, "R" = "Rough_HM_R(asper)")
data <- rename(data, "I" = "I_HM_I(iu)")
data <- rename(data, "FS" = "FS_(vacil)")
data <- rename(data, "LAeq" = "LAeq_L(A)(dB(SPL))")
data <- rename(data, "LA10_LA90" = "LA10_LA90(dB(SPL))")
data <- rename(data, "LCeq_LAeq" = "LCeq_LAeq(dB(SPL))")
data <- rename(data, "SIL3" = "SIL3_Avg,arith(dB(SPL))")
features <- c("N5", "S", "R", "I", "FS", "LAeq", "LA10_LA90", "LCeq_LAeq", "SIL3")
feature_string <- paste(features, collapse = " + ")
feature_string
print("Full data table has dimensions: ")
print(dim(data))
kable(print(data))
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
data <- data %>% mutate_at(vars(c("ISOPleasant", "ISOEventful", "Traffic", "Human", "Natural", features)), funs(as.numeric))
kable(head(data))
prelockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- data %>% filter(Lockdown == 2)
prelockdownData <- drop_na(prelockdownData)
prelockdownData[c(features)] <- scale(prelockdownData[c(features)])
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
kable(summary(train))
library(glmmLasso)
## generalized additive mixed model
## grid for the smoothing parameter
## center all metric variables so that also the starting values with glmmPQL are in the correct scaling
lassoData<-data.frame(prelockdownData)
lambda <- seq(500,0,by=-5)
family = gaussian(link = identity)
################## First Simple Method ############################################
## Using BIC (or AIC, respectively) to determine the optimal tuning parameter lambda
BIC_vec<-rep(Inf,length(lambda))
## first fit good starting model
library(MASS);library(nlme)
PQL<-glmmPQL(points~1,random = ~1|LocationID,family=family,data=lassoData)
library(glmmLasso)
## generalized additive mixed model
## grid for the smoothing parameter
## center all metric variables so that also the starting values with glmmPQL are in the correct scaling
lassoData<-data.frame(prelockdownData)
lambda <- seq(500,0,by=-5)
family = gaussian(link = identity)
################## First Simple Method ############################################
## Using BIC (or AIC, respectively) to determine the optimal tuning parameter lambda
BIC_vec<-rep(Inf,length(lambda))
## first fit good starting model
library(MASS);library(nlme)
PQL<-glmmPQL(ISOPleasant~1,random = ~1|LocationID,family=family,data=lassoData)
Delta.start<-c(as.numeric(PQL$coef$fixed),rep(0,6),as.numeric(t(PQL$coef$random$LocationID)))
Q.start<-as.numeric(VarCorr(PQL)[1,1])
for(j in 1:length(lambda))
{
print(paste("Iteration ", j,sep=""))
glm1 <- try(glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3,
rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[j],switch.NR=T,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start)), silent=TRUE)
if(class(glm1)!="try-error")
{
BIC_vec[j]<-glm1$bic
}
}
opt<-which.min(BIC_vec)
glm1_final <- glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3, rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[opt],switch.NR=F,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start))
BIC_cef
BIC_vec
library(glmmLasso)
## generalized additive mixed model
## grid for the smoothing parameter
## center all metric variables so that also the starting values with glmmPQL are in the correct scaling
lassoData<-data.frame(prelockdownData)
lambda <- seq(1000,0,by=-5)
family = gaussian(link = identity)
################## First Simple Method ############################################
## Using BIC (or AIC, respectively) to determine the optimal tuning parameter lambda
BIC_vec<-rep(Inf,length(lambda))
## first fit good starting model
library(MASS);library(nlme)
PQL<-glmmPQL(ISOPleasant~1,random = ~1|LocationID,family=family,data=lassoData)
Delta.start<-c(as.numeric(PQL$coef$fixed),rep(0,6),as.numeric(t(PQL$coef$random$LocationID)))
Q.start<-as.numeric(VarCorr(PQL)[1,1])
for(j in 1:length(lambda))
{
print(paste("Iteration ", j,sep=""))
glm1 <- try(glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3,
rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[j],switch.NR=T,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start)), silent=TRUE)
if(class(glm1)!="try-error")
{
BIC_vec[j]<-glm1$bic
}
}
opt<-which.min(BIC_vec)
glm1_final <- glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3, rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[opt],switch.NR=F,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start))
library(glmmLasso)
## generalized additive mixed model
## grid for the smoothing parameter
## center all metric variables so that also the starting values with glmmPQL are in the correct scaling
lassoData<-data.frame(prelockdownData)
control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5))
lambda <- seq(1000,0,by=-5)
family = gaussian(link = identity)
################## First Simple Method ############################################
## Using BIC (or AIC, respectively) to determine the optimal tuning parameter lambda
BIC_vec<-rep(Inf,length(lambda))
## first fit good starting model
library(MASS);library(nlme)
PQL<-glmmPQL(ISOPleasant~1,random = ~1|LocationID,family=family,data=lassoData, control = control)
Delta.start<-c(as.numeric(PQL$coef$fixed),rep(0,6),as.numeric(t(PQL$coef$random$LocationID)))
Q.start<-as.numeric(VarCorr(PQL)[1,1])
for(j in 1:length(lambda))
{
print(paste("Iteration ", j,sep=""))
glm1 <- try(glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3,
rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[j],switch.NR=T,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start)), silent=TRUE)
if(class(glm1)!="try-error")
{
BIC_vec[j]<-glm1$bic
}
}
opt<-which.min(BIC_vec)
glm1_final <- glmmLasso(ISOPleasant~N5 + S + R + I + FS + LAeq + LA10_LA90 + LCeq_LAeq + SIL3, rnd = list(LocationID=~1),
family = family, data = lassoData, lambda=lambda[opt],switch.NR=F,final.re=TRUE,
control=list(start=Delta.start,q_start=Q.start))
BIC_vec
opt
