train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity)
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity, plot=FALSE)
Pleasant.results
train
View(Pleasant.results)
train.pred <- train['LocationID']
train.pred$actual <- train['ISOPleasant'][[1]]
train.pred$pred <- predict(Pleasant.results$model)
Pleasant.results$model
View(Pleasant.results)
Pleasant.results$model$fitted
length(train)
length(train$ISOPleasant)
model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
train.data <- train
print(length(train.data[target]))
test.data <- test
if (scale) {
train.data[c(features)] <- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, data=train.data, reduce.random=TRUE)
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- pred.plots(model, target, train.data, test.data, grp=grp)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
pred.plots <- function(model, target, train, test, grp="LocationID") {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test.data)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity, plot=FALSE)
model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
train.data <- train
print(length(train.data[[target]))
model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
train.data <- train
print(length(train.data[[target]]))
test.data <- test
if (scale) {
train.data[c(features)] <- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, data=train.data, reduce.random=TRUE)
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- pred.plots(model, target, train.data, test.data, grp=grp)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
pred.plots <- function(model, target, train, test, grp="LocationID") {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test.data)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity, plot=FALSE)
length(train[c(features)])
length(train[[c(features)]])
is.na(train$ISOPleasant)
length(is.na(train$ISOPleasant))
count(is.na(train$ISOPleasant))
length(is.na(train$ISOPleasant)==FALSE)
length(is.na(train$N5))
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
data <- data %>% mutate_at(vars(Traffic, Human, Natural), funs(factor), order=TRUE)
data <- data %>% mutate_at(vars(c("ISOPleasant", "ISOEventful", features)), funs(as.numeric))
data <- data %>% filter(!if_any(c(ISOPleasant, ISOEventful, PA, N5, S, R, I, FS, T, LAeq, LA10_LA90, LC_LA, SIL3), is.na))
kable(head(data))
library(correlation)
corrs <- correlation::correlation(data[c(features, "LocationID")], multilevel=FALSE)
s <- summary(corrs)
s
prelockdownData <- data %>% filter(Lockdown == 0)
lockdownData <- data %>% filter(Lockdown == 1)
# prelockdownData <- drop_na(prelockdownData)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
kable(summary(train))
lenght(train)
length(train)
size(train)
dim(train)
kable(summary(test))
model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
train.data <- train
test.data <- test
if (scale) {
train.data[c(features)] <- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, data=train.data, reduce.random=TRUE)
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- pred.plots(model, target, train.data, test.data, grp=grp)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
pred.plots <- function(model, target, train, test, grp="LocationID") {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test.data)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity)
rlang::last_error()
rlang::last_trace()
model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(lmerTest, glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
train.data <- train
test.data <- test
if (scale) {
train.data[c(features)] <- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, data=train.data, reduce.random=TRUE)
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- pred.plots(model, target, train.data, test.data, grp=grp)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
pred.plots <- function(model, target, train, test, grp="LocationID") {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", exclude.features = c("SIL3"), verbose=verbosity)
Eventful.results <- model.building(target="ISOEventful", features = features, train = train, test = test, grp="LocationID", verbose=verbosity)
