# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
lm.model.building <- function(target, features, train, test, exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <<- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lm(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model)
if (verbose >= 2) {print(step.model)}
scaled.model <- step.model
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lm(formula, data=train)
if (verbose > 1) {
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model R-squared:")
# print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lm.pred.plots(model, target, train.data, test.data, grp="LocationID", plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lm.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
lm.location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, scale=TRUE)
# Eventful.results <- lmer.model.building("ISOEventful", features, train, test, verbose=1)
# Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, scale=TRUE)
Eventful.results <- lmer.model.building("ISOEventful", features, train, test, verbose=1)
car::vif(Eventful.results$model)
# Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, scale=TRUE)
Eventful.results <- lmer.model.building("ISOEventful", features, train, test, verbose=1, exclude.features = c("N5"))
sjPlot::tab_model(Pleasant.results$model, Eventful.results$model)
sjPlot::tab_model(Pleasant.results$scaled.model, Eventful.results$scaled.model)
sjPlot::plot_models(Pleasant.results$scaled.model, Eventful.results$scaled.model, std.est='std', show.values = TRUE)
Eventful.results$outliers <- performance::check_outliers(Eventful.results$model, method=c("cook"))
print(Eventful.results$outliers)
plot(Eventful.results$outliers)
library(performance)
prelockdownData <- data %>% filter(Lockdown == 0)
lockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- lockdownData %>% filter(!if_any(c(features), is.na))
prelockdownData <- prelockdownData %>% filter(!if_any(c("ISOPleasant", "ISOEventful", features), is.na))
# Check outliers
prelockdown.check <- check_outliers(prelockdownData[c(features)], method="ics")
print(prelockdown.check)
plot(prelockdown.check)
prelockdown.outliers <- as.data.frame(prelockdown.check)
prelockdownData <- prelockdownData[prelockdown.outliers$Outlier == 0, ]
# Check outliers
lockdown.check <- check_outliers(lockdownData[c(features)], method="ics")
print(lockdown.check)
plot(lockdown.check)
lockdown.outliers <- as.data.frame(lockdown.check)
lockdownData <- lockdownData[lockdown.outliers$Outlier == 0, ]
?ICSOutliser::ics.outlier()
?ICSOutlier::ics.outlier()
lockdownData$ISOPleasant <- predict(Pleasant.results$model, newdata=lockdownData)
lockdownData$ISOEventful <- predict(Eventful.results$model, newdata=lockdownData)
# lockdownData$Natural <- predict(Natural.mod, newdata=lockdownData)
# lockdownData$Human <- predict(Human.mod, newdata=lockdownData)
# lockdownData$Traffic <- predict(Traffic.mod, newdata=lockdownData)
print(head(lockdownData))
write.csv(lockdownData, glue("Predicted Lockdown Data_", format(Sys.Date()), "_1", ".csv"), row.names = FALSE)
knitr::opts_chunk$set(echo = TRUE)
verbosity = 1
init_features <- c("PA(Zwicker)", "Loudness_N5(soneGF)", "Sharpness_S(acum)", "Rough_HM_R(asper)", "I_HM_I(iu)", "FS_(vacil)", "Ton_HM_Avg,arith(tuHMS)", "LAeq_L(A)(dB(SPL))", "LA10_LA90(dB(SPL))", "LCeq_LAeq(dB(SPL))", "RA_2D_cp(cPa)")
init_feature_string <- paste(init_features, collapse = " + ")
init_feature_string
library(glue)
library(tidyr)
library(here)
library(knitr)
library(dplyr)
library(readxl)
data <- read_excel(here("data", "2021-05-18", "SSID Europe Database V1.0.xlsx"), sheet = "Master Merge")
data <- as_tibble(data)
data <- data[c("GroupID", "LocationID", "Lockdown", "ISOPleasant", "ISOEventful", init_features)]
data <- rename(data, "PA" = "PA(Zwicker)")
data <- rename(data, "N5" = "Loudness_N5(soneGF)")
data <- rename(data, "S" = "Sharpness_S(acum)")
data <- rename(data, "R" = "Rough_HM_R(asper)")
data <- rename(data, "I" = "I_HM_I(iu)")
data <- rename(data, "FS" = "FS_(vacil)")
data <- rename(data, "T" = "Ton_HM_Avg,arith(tuHMS)")
data <- rename(data, "LAeq" = "LAeq_L(A)(dB(SPL))")
data <- rename(data, "LA10_LA90" = "LA10_LA90(dB(SPL))")
data <- rename(data, "LC_LA" = "LCeq_LAeq(dB(SPL))")
data <- rename(data, "RA" = "RA_2D_cp(cPa)")
# data <- rename(data, "SIL3" = "SIL3_Avg,arith(dB(SPL))")
features <- c("PA", "N5", "S", "R", "I", "FS", "T", "LAeq", "LA10_LA90", "LC_LA", "RA")
feature_string <- paste(features, collapse = " + ")
feature_string
locations <- c("CamdenTown", "EustonTap", "MarchmontGarden", "MonumentoGaribaldi", "PancrasLock", "RegentsParkFields", "RegentsParkJapan", "RussellSq", "SanMarco", "StPaulsCross", "StPaulsRow", "TateModern", "TorringtonSq")
data <- data %>%
filter(LocationID %in% locations)
print(glue("Full data table has dimensions: ", dim(data)[1], ", ", dim(data)[2]))
kable(head(data))
data <- data %>% mutate_at(vars(GroupID, LocationID, Lockdown), funs(as.factor))
# data <- data %>% mutate_at(vars(Traffic, Human, Natural), funs(factor), order=TRUE)
data <- data %>% mutate_at(vars(c("ISOPleasant", "ISOEventful", features)), funs(as.numeric))
# kable(head(data))
library(performance)
prelockdownData <- data %>% filter(Lockdown == 0)
lockdownData <- data %>% filter(Lockdown == 1)
lockdownData <- lockdownData %>% filter(!if_any(c(features), is.na))
prelockdownData <- prelockdownData %>% filter(!if_any(c("ISOPleasant", "ISOEventful", features), is.na))
library(correlation)
corrs <- correlation::correlation(prelockdownData[c(features, "LocationID")], multilevel=FALSE)
s <- summary(corrs) %>% mutate_if(is.numeric, round, digits=2)
kable(s)
# Train-test split
library(groupdata2)
set.seed(42)
parts = partition(prelockdownData, p=0.2, cat_col="LocationID")
train = parts[[2]]
test = parts[[1]]
library(lmerTest)
lmer.model.building <- function(target, features, train, test, grp="LocationID", exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string, " + (1 + ", features.string, "|", grp, ")"))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <<- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lmer(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model, reduce.random=TRUE)
if (verbose >= 2) {print(step.model)}
scaled.model <- get_model(step.model)
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lmer(formula, data=train)
if (verbose > 1) {
print(step.model$fixed)
print(step.model$random)
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, type="re", title=glue("Random effects - ", target), show.values=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model MLM R-squared:")
print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lmer.pred.plots(model, target, train.data, test.data, grp=grp, plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lmer.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results <- lmer.model.building(target="ISOPleasant", features = features, train = train, test = test, grp="LocationID", verbose=verbosity, pred=TRUE, plot=TRUE)
lm.model.building <- function(target, features, train, test, exclude.features = NULL, scale=TRUE, pred = TRUE, plot = TRUE, print.loc.means = TRUE, verbose = 0, ...) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(glue, knitr, car, sjPlot, MuMIn, ggplot2, gridExtra, ModelMetrics)
# Remove the excluded features from the feature vector
if (length(exclude.features)>=1) {
features <- grep(paste0(exclude.features, collapse = "|"), features, invert=TRUE, value=TRUE)
}
features.string <- paste(features, collapse = " + ")
formula <- as.formula(glue(target, " ~ 1 + ", features.string))
test.data <<- test
train.data <<- train
if (scale) {
train.data[c(features)] <<- scale(train.data[c(features)])
}
# Fit initial model and run stepwise feature selection
if (verbose > 0) {print("Fitting initial model.")}
init.model <- lm(formula, data=train.data)
if (verbose >= 2) {print(summary(init.model))}
if (verbose > 0) {print("Performing Feature Selection")}
step.model <- step(init.model)
if (verbose >= 2) {print(step.model)}
scaled.model <- step.model
formula <- formula(scaled.model)
if (verbose > 0) {print("Fitting Final Model")}
model <- lm(formula, data=train)
if (verbose > 1) {
print(summary(model))
}
# kable(vif(model))
results <- list("step.results" = step.model, "model" = model, "scaled.model"=scaled.model)
if (plot | pred) {
# print(tab_model(model, show.icc=TRUE, collapse.ci=TRUE, show.aic=TRUE))
print(plot_model(scaled.model, show.values=TRUE))
print("Trained model R-squared:")
# print(r.squaredGLMM(model))
# Generating predictions and evaluating for training and test set
pred.results <- lm.pred.plots(model, target, train.data, test.data, grp="LocationID", plot=plot)
results[["pred.results"]] = pred.results
means <- location.score(results, print=print.loc.means)
results[["train.means"]] = means$train.means
results[["test.means"]] = means$test.means
results[["train.loc.mae"]] = means$train.loc.mae
results[["train.loc.r2"]] = means$train.loc.r2
results[["test.loc.mae"]] = means$test.loc.mae
results[["test.loc.r2"]] = means$test.loc.r2
}
results
}
lm.pred.plots <- function(model, target, train, test, grp="LocationID", plot) {
if (!require("pacman")) install.packages("pacman")
pacman::p_load(knitr, ModelMetrics, gridExtra, ggplot2, glue)
train.pred <- train[grp]
train.pred$actual <- train[target][[1]]
train.pred$pred <- predict(model)
test.pred <- test[grp]
test.pred$actual <- test[target][[1]]
test.pred$pred <- predict(model, newdata=test)
# Calculate the normalised RMSE
# range <- abs(max(train.pred$actual) - min(train.pred$actual))
train.mae <- mae(train.pred$pred, train.pred$actual)
test.mae <- mae(test.pred$pred, test.pred$actual)
if (plot) {
# Plot predicted vs actual
test.title <- glue("Test Set (MAE=", round(test.mae, 3), ")", sep="")
test.plot <- ggplot(test.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=test.title)+
coord_fixed() +
theme(legend.position="none")
train.title <- glue("Train Set (MAE=", round(train.mae, 3), ")", sep="")
train.plot <- ggplot(train.pred, aes(x=pred, y=actual, colour=LocationID)) +
geom_point() +
geom_abline(intercept=0, slope=1) +
labs(x = 'Predicted Values', y='Actual Values', title=train.title) +
coord_fixed() +
theme(legend.position="none")
grid.arrange(train.plot, test.plot, nrow=1)
}
results <- list("train.pred" = train.pred, "test.pred" = test.pred, "test.mae" = test.mae, "train.mae" = train.mae)
}
lm.location.score <- function(model.results, print=TRUE) {
pacman::p_load(dplyr, ModelMetrics, MLmetrics, glue)
pred.results <- model.results$pred.results
train.pred <- pred.results$train.pred
test.pred <- pred.results$test.pred
model <- model.results$model
train.means <- train.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
test.means <- test.pred %>%
group_by(LocationID) %>%
summarise_at(vars(actual, pred), funs(mean(., na.rm=TRUE)))
train.loc.mae <- mae(train.means$pred, train.means$actual)
train.loc.r2 <- R2_Score(train.means$pred, train.means$actual)
test.loc.mae <- mae(test.means$pred, test.means$actual)
test.loc.r2 <- R2_Score(test.means$pred, test.means$actual)
if (print) {
print(glue("Train Location R^2: ", round(train.loc.r2, 3)))
print(glue("Test Location R^2:  ", round(test.loc.r2, 3)))
}
results <- list(
"train.means" = train.means,
"test.means" = test.means,
"train.loc.mae" = train.loc.mae,
"train.loc.r2" = train.loc.r2,
"test.loc.mae" = test.loc.mae,
"test.loc.r2" = test.loc.r2)
}
Pleasant.results$outliers <- performance::check_outliers(Pleasant.results$model, method=c("cook"))
print(Pleasant.results$outliers)
plot(Pleasant.results$outliers)
influence(Pleasant.results$model)
Pleasant.results$model
influence.measures(Pleasant.results$model)
??influencePlot.lmerMod
car::influencePlot(Pleasant.results$model)
outlierTest(Pleasant.results$model)
qqPlot(Pleasant.results$model)
leveragePlots(Pleasant.results$model)
plot_model(Pleasant.results$model, type="resid")
crPlots(Pleasant.results$model)
crPlots(Eventful.results$model)
plot_model(Pleasant.results$model, type="pred")
plot_model(Pleasant.results$model, type="eff")
plot_model(Pleasant.results$model, type="slope")
plot_model(Eventful.results$model, type="slope")
plot_model(Pleasant.results$model, type="diag")
plot_model(Eventful.results$model, type="diag")
plot_model(Pleasant.results$model, type="resid")
plot_model(Pleasant.results$model, type="diag")
plot_model(Pleasant.results$model, type="slope")
plot_model(Pleasant.results$scaled.model, type="slope")
plot_model(Pleasant.results$model, type="slope")
plot_model(Pleasant.results$model, type="eff", terms="N5")
plot_model(Pleasant.results$model, type="eff", terms="LAeq")
Eventful.results <- lm.model.building(target="ISOEventful", features=features, train = train, test = test, verbose=2, pred=TRUE, plot=TRUE, scale=TRUE, exclude.features = c("N5"))
plot_model(Eventful.results$model, type="eff", terms="LAeq")
plot_model(Eventful.results$model, type="slope", terms="LAeq")
plot_model(Eventful.results$model, type="slope", terms="S")
plot_model(Eventful.results$model, type="slope", terms="FS")
plot_model(Eventful.results$model, type="slope", terms="T")
plot_model(Eventful.results$model, type="slope", terms="LC_LA")
plot_model(Eventful.results$model, type="slope", terms="T")
